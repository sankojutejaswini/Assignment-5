PCA vs LDA
Both PCA and LDA are linear transformation techniques. However, PCA is an unsupervised while LDA is a supervised dimensionality reduction technique.

Principal Component Analysis:
PCA summarizes the feature set without relying on the output. PCA tries to find the directions of the maximum variance in the dataset.
In a large feature set, there are many features that are merely duplicate of the other features or have a high correlation with the other features.
Such features are basically redundant and can be ignored. The role of PCA is to find such highly correlated or duplicate features and to come up with a 
new feature set where there is minimum correlation between the features or in other words feature set with maximum variance between the features. 
Since the variance between the features doesn't depend upon the output, therefore PCA doesn't take the output labels into account.

Linear Discriminant Analysis:
LDA tries to reduce dimensions of the feature set while retaining the information that discriminates output classes.
LDA tries to find a decision boundary around each cluster of a class. It then projects the data points to new dimensions in a way that the clusters are as
separate from each other as possible and the individual elements within a cluster are as close to the centroid of the cluster as possible.
The new dimensions are ranked on the basis of their ability to maximize the distance between the clusters and minimize the distance between the data points
within a cluster and their centroids. These new dimensions form the linear discriminants of the feature set.
